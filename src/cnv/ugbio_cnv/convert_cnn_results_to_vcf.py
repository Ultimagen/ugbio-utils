import argparse
import logging
import subprocess
import sys
import warnings
from os.path import join as pjoin

import pandas as pd
import pysam
from ugbio_core.logger import logger

warnings.filterwarnings("ignore")


def add_cnmops_vcf_header(sample_name: str, fasta_index_file: str) -> pysam.VariantHeader:
    header = pysam.VariantHeader()

    # Add meta-information to the header
    header.add_meta("fileformat", value="VCFv4.2")
    header.add_meta("source", value="ULTIMA_CNV")

    # Add sample names to the header
    header.add_sample(sample_name)

    # Add contigs info to the header
    df_genome = pd.read_csv(fasta_index_file, sep="\t", header=None, usecols=[0, 1])
    df_genome.columns = ["chr", "length"]
    for _, row in df_genome.iterrows():
        chr_id = row["chr"]
        length = row["length"]
        header.add_line(f"##contig=<ID={chr_id},length={length}>")

    header.filters.add("LowQual", None, None, "Variant with QUAL < 0.1")

    # Add INFO
    header.add_line('##INFO=<ID=probability,Number=1,Type=Float,Description="CNN probability">')
    header.add_line('##INFO=<ID=SVLEN,Number=.,Type=Integer,Description="CNV length">')
    header.add_line('##INFO=<ID=SVTYPE,Number=1,Type=String,Description="CNV type. can be DUP or DEL">')

    return header


def write_cnmops_vcf(outfile: str, header: pysam.VariantHeader, cnv_annotated_bed_file: str, sample_name: str) -> None:
    """
    Write CNV calls from a cn.mops BED file to a VCF file.
    Args:
        outfile (str): Path to the output VCF file.
        header (pysam.VariantHeader): VCF header with reference genome information.
        cnv_annotated_bed_file (str): Path to the input BED file containing CNV calls generated by cn.mops and
            annotated with UG-CNV-LCR.
        sample_name (str): Name of the sample.
    """
    with pysam.VariantFile(outfile, mode="w", header=header) as vcf_out:
        df_cnvs = pd.read_csv(cnv_annotated_bed_file, sep=",", skipinitialspace=True)
        df_cnvs.columns = ["chr", "start", "end", "info"]
        for _, row in df_cnvs.iterrows():
            # Create a new VCF record
            chr_id = row["chr"]
            start = row["start"]
            end = row["end"]
            probability = row["info"]

            record = vcf_out.new_record()
            record.contig = chr_id
            record.start = start
            record.stop = end
            record.ref = "N"
            record.qual = probability

            record.info["SVLEN"] = int(end) - int(start)
            record.info["SVTYPE"] = "DEL"
            record.info["probability"] = probability
            # END position is automatically generated for multi-base variants

            qual_cutoff = 0.2510235
            if record.qual is not None and record.qual > qual_cutoff:
                record.filter.clear()  # this means "PASS" in VCF
                record.filter.add("PASS")
            else:
                record.filter.add("LowQual")

            # Write the record to the VCF file
            vcf_out.write(record)


def run(argv):
    """
    converts CNV calls in bed format to vcf.
    input arguments:
    --cnv_annotated_bed_file: input bed file holding CNV calls.
    --fasta_index_file: (.fai file) tab delimeted file holding reference genome chr ids with their lengths.
    --out_directory: output directory
    --sample_name: sample name
    output files:
    vcf file: <sample_name>.cnv.vcf.gz
        shows called CNVs in zipped vcf format.
    vcf index file: <sample_name>.cnv.vcf.gz.tbi
        vcf corresponding index file.
    """
    parser = argparse.ArgumentParser(prog="convert_cnn_results_to_vcf.py", description="converts CNN results into vcf.")

    parser.add_argument("--CNN_output", help="input file holding CNN results", required=True, type=str)
    parser.add_argument(
        "--fasta_index_file",
        help="tab delimeted file holding reference genome chr ids with their lengths. (.fai file)",
        required=True,
        type=str,
    )
    parser.add_argument("--out_directory", help="output directory", required=False, type=str)
    parser.add_argument("--sample_name", help="sample name", required=True, type=str)
    parser.add_argument("--verbosity", help="Verbosity: ERROR, WARNING, INFO, DEBUG", required=False, default="INFO")

    args = parser.parse_args(argv[1:])
    logger.setLevel(getattr(logging, args.verbosity))
    sample_name = args.sample_name
    header = add_cnmops_vcf_header(sample_name, args.fasta_index_file)

    # Open a VCF file for writing
    if args.out_directory:
        out_directory = args.out_directory
    else:
        out_directory = ""
    outfile = pjoin(out_directory, sample_name + ".cnv.unsorted.vcf.gz")

    write_cnmops_vcf(outfile, header, args.CNN_output, args.sample_name)

    try:
        outfile_sorted = pjoin(out_directory, sample_name + ".cnv.vcf.gz")
        cmd = ["bcftools", "sort", "-Oz", "-o", outfile_sorted, outfile]
        subprocess.check_call(cmd)
        cmd = ["bcftools", "index", "-t", outfile_sorted]
        subprocess.check_call(cmd)
    except subprocess.CalledProcessError as e:
        print(f"bcftools index command failed with exit code: {e.returncode}")
        sys.exit(1)  # Exit with error status
    logger.info(f"output file: {outfile_sorted}")
    logger.info(f"output file index: {outfile_sorted}.tbi")


def main():
    run(sys.argv)


if __name__ == "__main__":
    main()
